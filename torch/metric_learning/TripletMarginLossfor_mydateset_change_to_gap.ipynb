{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Howl06/classify_project/blob/main/metric_learning_test/TripletMarginLossfor_mydateset_change_to_gap.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S6r2sKa4I9x_",
        "outputId": "a118935a-e72d-4a79-df97-7c78f9cb3245"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lMde13VLDjiH",
        "outputId": "4a74a295-ea56-4752-8233-b8428d499d91"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pytorch-metric-learning\n",
            "  Downloading pytorch_metric_learning-2.1.1-py3-none-any.whl (110 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.8/110.8 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from pytorch-metric-learning) (1.22.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from pytorch-metric-learning) (1.2.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from pytorch-metric-learning) (4.65.0)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-metric-learning) (2.0.0+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->pytorch-metric-learning) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->pytorch-metric-learning) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->pytorch-metric-learning) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->pytorch-metric-learning) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->pytorch-metric-learning) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->pytorch-metric-learning) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->pytorch-metric-learning) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->pytorch-metric-learning) (16.0.3)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->pytorch-metric-learning) (1.10.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->pytorch-metric-learning) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->pytorch-metric-learning) (3.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6.0->pytorch-metric-learning) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->pytorch-metric-learning) (1.3.0)\n",
            "Installing collected packages: pytorch-metric-learning\n",
            "Successfully installed pytorch-metric-learning-2.1.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting faiss-gpu\n",
            "  Downloading faiss_gpu-1.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (85.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.5/85.5 MB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faiss-gpu\n",
            "Successfully installed faiss-gpu-1.7.2\n"
          ]
        }
      ],
      "source": [
        "!pip install pytorch-metric-learning\n",
        "!pip install faiss-gpu"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/drive/MyDrive/model/deep-learning-for-image-processing-master/data_set/project_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8TRH40bvLchA",
        "outputId": "19d366e1-caec-446c-9e21-f80ef2cb831f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/model/deep-learning-for-image-processing-master/data_set/project_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GJ_L0TrTDnEA",
        "outputId": "d7f05665-4b35-460f-d051-5ce40f61e013"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "using cuda:0 device.\n",
            "Epoch 1 Iteration 0: Loss = 0.12824690341949463, Number of mined triplets = 6311\n",
            "Epoch 1 Iteration 20: Loss = 0.10782115906476974, Number of mined triplets = 1813\n",
            "Epoch 1 Iteration 40: Loss = 0.10814627259969711, Number of mined triplets = 1222\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 83/83 [04:57<00:00,  3.59s/it]\n",
            "100%|██████████| 21/21 [04:59<00:00, 14.25s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Computing accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/faiss/contrib/torch_utils.py:51: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  x.storage().data_ptr() + x.storage_offset() * 4)\n",
            "/usr/local/lib/python3.10/dist-packages/faiss/contrib/torch_utils.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  x.storage().data_ptr() + x.storage_offset() * 8)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test set accuracy (Precision@1) = 0.40279937791601866\n",
            "Epoch 2 Iteration 0: Loss = 0.09959603101015091, Number of mined triplets = 1328\n",
            "Epoch 2 Iteration 20: Loss = 0.10293367505073547, Number of mined triplets = 903\n",
            "Epoch 2 Iteration 40: Loss = 0.10758243501186371, Number of mined triplets = 1308\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 83/83 [04:57<00:00,  3.59s/it]\n",
            "100%|██████████| 21/21 [01:16<00:00,  3.64s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Computing accuracy\n",
            "Test set accuracy (Precision@1) = 0.39035769828926903\n",
            "Epoch 3 Iteration 0: Loss = 0.10617554932832718, Number of mined triplets = 1083\n",
            "Epoch 3 Iteration 20: Loss = 0.10893814265727997, Number of mined triplets = 1243\n",
            "Epoch 3 Iteration 40: Loss = 0.10417734086513519, Number of mined triplets = 1066\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 83/83 [04:57<00:00,  3.58s/it]\n",
            "100%|██████████| 21/21 [01:15<00:00,  3.60s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Computing accuracy\n",
            "Test set accuracy (Precision@1) = 0.4214618973561431\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "### MNIST code originally from https://github.com/pytorch/examples/blob/master/mnist/main.py ###\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "from pytorch_metric_learning import distances, losses, miners, reducers, testers\n",
        "from pytorch_metric_learning.utils.accuracy_calculator import AccuracyCalculator\n",
        "\n",
        "\n",
        "### MNIST code originally from https://github.com/pytorch/examples/blob/master/mnist/main.py ###\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 32, 3, 1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
        "        self.dropout1 = nn.Dropout2d(0.25)\n",
        "        self.dropout2 = nn.Dropout2d(0.5)\n",
        "        self.gab = nn.AdaptiveAvgPool2d(1)\n",
        "        self.fc1 = nn.Linear(64, 128)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x) # batchsize 3 224 224  -> batchsize 32 224 224 \n",
        "        x = F.relu(x)\n",
        "        x = self.conv2(x) # batchsize 32 224 224  -> batchsize 64 224 224 \n",
        "        x = F.relu(x)\n",
        "        x = F.max_pool2d(x, 2) # batchsize 64 224 224 -> batchsize 64 112 112\n",
        "        x = self.dropout1(x)\n",
        "        x = self.gab(x)     # batchsize 64 112 112 -> batchsize 64 1\n",
        "        x = torch.flatten(x, 1) # batchsize 64 1 -> batchsize 64\n",
        "        x = self.fc1(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "### MNIST code originally from https://github.com/pytorch/examples/blob/master/mnist/main.py ###\n",
        "def train(model, loss_func, mining_func, device, train_loader, optimizer, epoch):\n",
        "    model.train()\n",
        "    for batch_idx, (data, labels) in enumerate(train_loader):\n",
        "        data, labels = data.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        embeddings = model(data)\n",
        "        indices_tuple = mining_func(embeddings, labels)\n",
        "        loss = loss_func(embeddings, labels, indices_tuple)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if batch_idx % 20 == 0:\n",
        "            print(\n",
        "                \"Epoch {} Iteration {}: Loss = {}, Number of mined triplets = {}\".format(\n",
        "                    epoch, batch_idx, loss, mining_func.num_triplets\n",
        "                )\n",
        "            )\n",
        "\n",
        "\n",
        "### convenient function from pytorch-metric-learning ###\n",
        "def get_all_embeddings(dataset, model):\n",
        "    tester = testers.BaseTester()\n",
        "    return tester.get_all_embeddings(dataset, model)\n",
        "\n",
        "\n",
        "### compute accuracy using AccuracyCalculator from pytorch-metric-learning ###\n",
        "def test(train_set, test_set, model, accuracy_calculator):\n",
        "    train_embeddings, train_labels = get_all_embeddings(train_set, model)\n",
        "    test_embeddings, test_labels = get_all_embeddings(test_set, model)\n",
        "    train_labels = train_labels.squeeze(1)\n",
        "    test_labels = test_labels.squeeze(1)\n",
        "    print(\"Computing accuracy\")\n",
        "    accuracies = accuracy_calculator.get_accuracy(\n",
        "        test_embeddings, test_labels, train_embeddings, train_labels, False\n",
        "    )\n",
        "    print(\"Test set accuracy (Precision@1) = {}\".format(accuracies[\"precision_at_1\"]))\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"using {} device.\".format(device))\n",
        "\n",
        "transform = transforms.Compose(\n",
        "    [transforms.Resize(224+32),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.5232674, 0.49784118, 0.42335856], [0.24051566, 0.23351395, 0.23727049])]\n",
        ")\n",
        "\n",
        "batch_size = 64\n",
        "\n",
        "\n",
        "#　dataset1 = datasets.MNIST(\".\", train=True, download=True, transform=transform)\n",
        "train_dataset = datasets.ImageFolder(root=\"./train/\",\n",
        "                                         transform=transform)\n",
        "valid_dataset = datasets.ImageFolder(root=\"./val/\",\n",
        "                                         transform=transform)\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    train_dataset, batch_size=batch_size, shuffle=True\n",
        ")\n",
        "test_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=batch_size)\n",
        "\n",
        "model = Net().to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "num_epochs = 3\n",
        "\n",
        "\n",
        "### pytorch-metric-learning stuff ###\n",
        "distance = distances.CosineSimilarity()\n",
        "reducer = reducers.ThresholdReducer(low=0)\n",
        "loss_func = losses.TripletMarginLoss(margin=0.2, distance=distance, reducer=reducer)\n",
        "mining_func = miners.TripletMarginMiner(\n",
        "    margin=0.2, distance=distance, type_of_triplets=\"semihard\"\n",
        ")\n",
        "accuracy_calculator = AccuracyCalculator(include=(\"precision_at_1\",), k=1)\n",
        "### pytorch-metric-learning stuff ###\n",
        "\n",
        "\n",
        "for epoch in range(1, num_epochs + 1):\n",
        "    train(model, loss_func, mining_func, device, train_loader, optimizer, epoch)\n",
        "    test(train_dataset, valid_dataset, model, accuracy_calculator)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3.8.10 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "vscode": {
      "interpreter": {
        "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
      }
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}